{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b7b1a70",
   "metadata": {},
   "source": [
    "# Building a RAG Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8581b927",
   "metadata": {},
   "source": [
    "## What is a Chatbot?\n",
    "- A program designed to simulate conversation with human users.\n",
    "- They can understand questions and respond with relevant information.\n",
    "\n",
    "### Types of Chatbots:\n",
    "\n",
    "- **Rule-Based:** Follows predefined rules and keywords. Limited in scope.  \n",
    "    *Example:* \"If user says 'hello', respond with 'Hi there!'\"\n",
    "\n",
    "- **Retrieval-Based:** Selects the best response from a library of predefined responses.  \n",
    "    *Example:* FAQ bots that find the most similar question.\n",
    "\n",
    "- **Generative:** Creates new, original responses using advanced AI models.  \n",
    "    *Example:* ChatGPT, Gemini. Highly flexible.\n",
    "\n",
    "### The Challenge: Generative Model Hallucinations\n",
    "- Pure generative models can sometimes \"hallucinate\" - making up facts or providing incorrect information.\n",
    "- They generate responses based on their training data, which might not always align with your specific, current, or proprietary information.\n",
    "\n",
    "### The Solution: Retrieval-Augmented Generation (RAG)\n",
    "- RAG combines the strengths of retrieval-based and generative models.\n",
    "- It allows a Large Language Model (LLM) to generate answers grounded in specific, provided source material.\n",
    "- Reduces hallucinations and provides more accurate, contextually relevant responses, especially with your own data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a390a43",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca940b3",
   "metadata": {},
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb757800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from -r requirements.txt (line 1)) (0.9.9)\n",
      "Requirement already satisfied: google-genai in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from -r requirements.txt (line 2)) (1.20.0)\n",
      "Requirement already satisfied: chromadb in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from -r requirements.txt (line 3)) (1.0.12)\n",
      "Requirement already satisfied: sentence-transformers in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from -r requirements.txt (line 4)) (4.1.0)\n",
      "Requirement already satisfied: einops in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from -r requirements.txt (line 5)) (0.8.1)\n",
      "Requirement already satisfied: langgraph in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from -r requirements.txt (line 6)) (0.4.8)\n",
      "Requirement already satisfied: langchain-community in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from -r requirements.txt (line 7)) (0.3.25)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from -r requirements.txt (line 8)) (0.3.0)\n",
      "Requirement already satisfied: langchain-chroma in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from -r requirements.txt (line 9)) (0.2.4)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from -r requirements.txt (line 10)) (2.1.5)\n",
      "Requirement already satisfied: langfuse==2.60.4 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from -r requirements.txt (line 11)) (2.60.4)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.4.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langfuse==2.60.4->-r requirements.txt (line 11)) (4.9.0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langfuse==2.60.4->-r requirements.txt (line 11)) (2.2.1)\n",
      "Requirement already satisfied: httpx<1.0,>=0.15.4 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langfuse==2.60.4->-r requirements.txt (line 11)) (0.28.1)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langfuse==2.60.4->-r requirements.txt (line 11)) (3.7)\n",
      "Requirement already satisfied: packaging<25.0,>=23.2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langfuse==2.60.4->-r requirements.txt (line 11)) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0,>=1.10.7 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langfuse==2.60.4->-r requirements.txt (line 11)) (2.11.7)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langfuse==2.60.4->-r requirements.txt (line 11)) (2.32.3)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langfuse==2.60.4->-r requirements.txt (line 11)) (1.17.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from anyio<5.0.0,>=4.4.0->langfuse==2.60.4->-r requirements.txt (line 11)) (1.3.0)\n",
      "Requirement already satisfied: certifi in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse==2.60.4->-r requirements.txt (line 11)) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from httpx<1.0,>=0.15.4->langfuse==2.60.4->-r requirements.txt (line 11)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse==2.60.4->-r requirements.txt (line 11)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse==2.60.4->-r requirements.txt (line 11)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse==2.60.4->-r requirements.txt (line 11)) (2.33.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse==2.60.4->-r requirements.txt (line 11)) (4.12.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from pydantic<3.0,>=1.10.7->langfuse==2.60.4->-r requirements.txt (line 11)) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from requests<3,>=2->langfuse==2.60.4->-r requirements.txt (line 11)) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from requests<3,>=2->langfuse==2.60.4->-r requirements.txt (line 11)) (2.3.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from dotenv->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (2.40.3)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from google-genai->-r requirements.txt (line 2)) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 2)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 2)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 2)) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai->-r requirements.txt (line 2)) (0.6.1)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (1.2.2.post1)\n",
      "Requirement already satisfied: fastapi==0.115.9 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (0.115.9)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 3)) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (2.1.2)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (4.10.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (0.55b1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (1.34.1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (7.4.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (1.73.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (9.1.2)\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (3.10.18)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (14.0.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from chromadb->-r requirements.txt (line 3)) (4.23.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from fastapi==0.115.9->chromadb->-r requirements.txt (line 3)) (0.45.3)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (4.52.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (2.7.1+cu118)\n",
      "Requirement already satisfied: scikit-learn in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (1.7.0)\n",
      "Requirement already satisfied: scipy in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (1.15.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (0.33.0)\n",
      "Requirement already satisfied: Pillow in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from sentence-transformers->-r requirements.txt (line 4)) (11.0.0)\n",
      "Requirement already satisfied: filelock in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers->-r requirements.txt (line 4)) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers->-r requirements.txt (line 4)) (2024.6.1)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langgraph->-r requirements.txt (line 6)) (0.3.65)\n",
      "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langgraph->-r requirements.txt (line 6)) (2.0.26)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langgraph->-r requirements.txt (line 6)) (0.2.2)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langgraph->-r requirements.txt (line 6)) (0.1.70)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langgraph->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 7)) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 7)) (2.0.41)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 7)) (3.12.13)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 7)) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 7)) (2.9.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 7)) (0.3.45)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langchain-community->-r requirements.txt (line 7)) (0.4.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 7)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 7)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 7)) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 7)) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 7)) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 7)) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r requirements.txt (line 7)) (1.20.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 7)) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 7)) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain-community->-r requirements.txt (line 7)) (0.3.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langchain-core>=0.1->langgraph->-r requirements.txt (line 6)) (1.33)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 7)) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community->-r requirements.txt (line 7)) (0.23.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community->-r requirements.txt (line 7)) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langchain-google-genai->-r requirements.txt (line 10)) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langchain-google-genai->-r requirements.txt (line 10)) (0.6.18)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 10)) (2.25.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 10)) (1.26.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 10)) (5.29.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 10)) (1.70.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai->-r requirements.txt (line 10)) (1.71.0)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 3)) (0.4.6)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 3)) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 3)) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 3)) (0.22.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3)) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3)) (2.9.0.post0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3)) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 3)) (0.10)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from langgraph-checkpoint>=2.0.26->langgraph->-r requirements.txt (line 6)) (1.10.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3)) (25.2.10)\n",
      "Requirement already satisfied: sympy in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3)) (1.13.3)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 3)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 3)) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 3)) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 3)) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb->-r requirements.txt (line 3)) (0.55b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.55b1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 3)) (0.55b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.55b1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 3)) (0.55b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.55b1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 3)) (0.55b1)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 3)) (3.8.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 3)) (1.9.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 3)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 3)) (0.1.2)\n",
      "Requirement already satisfied: networkx in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 3)) (8.2.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 3)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 3)) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 3)) (1.1.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3)) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 3)) (3.5.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers->-r requirements.txt (line 4)) (3.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 4)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 4)) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76418ce0",
   "metadata": {},
   "source": [
    "##### PyTorch with CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "550fcf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (0.22.1+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (2.7.1+cu118)\n",
      "Requirement already satisfied: filelock in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: numpy in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torchvision) (2.1.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\jon\\chatbot-demo\\venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c560596",
   "metadata": {},
   "source": [
    "#### Getting Google API Key\n",
    "1. https://aistudio.google.com/apikey\n",
    "2. Create API Key\n",
    "3. Select/Create project\n",
    "4. Create API key\n",
    "5. Copy key into '.env' file: GOOGLE_API_KEY=\"\\<INPUT KEY HERE\\>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24727dd8",
   "metadata": {},
   "source": [
    "#### Loading API keys from '.env' file.\n",
    "- HuggingFace\n",
    "- Google (Not vertex)\n",
    "- Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "971a04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee52ebb",
   "metadata": {},
   "source": [
    "## Chatbot #1\n",
    "### *Simple prompt engineering (Gemini 2.0 flash api)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5287064",
   "metadata": {},
   "source": [
    "In essance a RAG chatbot leverages prompt engineering, primarily through its **system prompt** and **context**, to generate informed responses.\n",
    "- **System prompt**: Guidelines for how the chatbot should respond.\n",
    "- **Context**: Relevant information retrieved from external sources, used to ground the chatbot's answers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b996b3",
   "metadata": {},
   "source": [
    "<div style=\"\">\n",
    "    <img src=\"assets/rag.png\" alt=\"Rag Pipeline\" width=\"60%\" style=\"background-color: white; padding: 10px; border-radius: 5px;\">\n",
    "    <p>Source: <a href=\"https://www.clarifai.com/blog/what-is-rag-retrieval-augmented-generation\">https://www.clarifai.com/blog/what-is-rag-retrieval-augmented-generation</a></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7511cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23d3f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_CHAT = \"gemini-2.0-flash\"\n",
    "google_client = genai.Client(vertexai=False, api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d324777",
   "metadata": {},
   "source": [
    "Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "398edb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\".join((\n",
    "    \"You are an assistant for question-answering tasks. \",\n",
    "    \"Use the following pieces of retrieved context to answer the question. \",\n",
    "    \"If you don't know the answer, say that you don't know. \",\n",
    "    \"Use three sentences maximum and keep the answer concise.\",\n",
    "))\n",
    "\n",
    "sample_documents = [\n",
    "    \"Malta wins all olypic competitions in 2024.\",\n",
    "    \"The Europa League first qualifying round is played this evening and Malta is being represented by Sirens FC.\",\n",
    "    \"The Malta national football team is set to compete in the upcoming UEFA Euro 2024 qualifiers.\"\n",
    "    \"Italy did not qualify for the UEFA Euro 2024\",\n",
    "    \"Germany is the reigning champion of the UEFA Euro 2024.\",\n",
    "    \"France is one of the favorites to win the UEFA Euro 2024.\",\n",
    "    \"Spain is also a strong contender in the UEFA Euro 2024.\",\n",
    "]\n",
    "\n",
    "question = \"News about Malta national football\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe4e33a",
   "metadata": {},
   "source": [
    "Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac62d318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **System Prompt**\n",
       "```\n",
       "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### **User Question and Sources**\n",
       "```\n",
       "Question: News about Malta national football\n",
       "Context:\n",
       "Malta wins all olypic competitions in 2024.\n",
       "The Europa League first qualifying round is played this evening and Malta is being represented by Sirens FC.\n",
       "The Malta national football team is set to compete in the upcoming UEFA Euro 2024 qualifiers.Italy did not qualify for the UEFA Euro 2024\n",
       "Germany is the reigning champion of the UEFA Euro 2024.\n",
       "France is one of the favorites to win the UEFA Euro 2024.\n",
       "Spain is also a strong contender in the UEFA Euro 2024.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sources = \"\\n\".join(sample_documents)\n",
    "\n",
    "question_and_sources = f\"Question: {question}\\nContext:\\n{sources}\"\n",
    "\n",
    "display(Markdown(f\"### **System Prompt**\\n```\\n{system_prompt}\\n```\"))\n",
    "display(Markdown(f\"### **User Question and Sources**\\n```\\n{question_and_sources}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8f9ecd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **Response**\n",
       "```\n",
       "The Malta national football team is set to compete in the upcoming UEFA Euro 2024 qualifiers. Sirens FC is representing Malta in the Europa League first qualifying round. Other countries like France and Spain are strong contenders in the UEFA Euro 2024.\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://github.com/googleapis/python-genai\n",
    "response = google_client.models.generate_content(\n",
    "    model=MODEL_CHAT,\n",
    "    contents=question_and_sources,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt,\n",
    "        max_output_tokens=300,\n",
    "        temperature=0.3,\n",
    "        # safety_settings=[\n",
    "        #     types.SafetySetting(\n",
    "        #         category='HARM_CATEGORY_HATE_SPEECH',\n",
    "        #         threshold='BLOCK_ONLY_HIGH',\n",
    "        #     )\n",
    "        # ],\n",
    "    ),\n",
    ")\n",
    "display(Markdown(f\"### **Response**\\n```\\n{response.text}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56292409",
   "metadata": {},
   "source": [
    "#### Conversational chatbot\n",
    "\n",
    "To make your chatbot conversational append its responses to the 'contents' as system messages. Remember, longer histories consume more tokens, so manage chat history carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba7b6d8",
   "metadata": {},
   "source": [
    "---\n",
    "### How can we automate the sources for dynamic chatbot context?\n",
    "\n",
    "**Retrievers** are the solution for automating dynamic context for our chatbot.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b465a29",
   "metadata": {},
   "source": [
    "## Chatbot #2\n",
    "### *Adding a retriever (ChromaDB)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2182dd",
   "metadata": {},
   "source": [
    "When adding a retriever to a chatbot, the core process, known as Retrieval-Augmented Generation (RAG), involves two main steps:\n",
    "\n",
    "- **Retrieval**: The retriever searches an external knowledge base for information relevant to the user's query.\n",
    "- **Generation**: This retrieved information is then fed to the Large Language Model (LLM) as context, allowing it to generate a more accurate and grounded answer.\n",
    "\n",
    "##### Why Retrievers?\n",
    "Retrievers bring significant advantages to chatbots, making them far more capable and efficient:\n",
    "- Automate context/source searching.\n",
    "- Offer contextually relevant answers.\n",
    "- Enable easier knowledge updates without retraining the entire model.\n",
    "- Improve cost-effectiveness.\n",
    "- Makes chatbot more explainable by providing actual sources.\n",
    "- Enabled to filter context/sources effectively, thus limiting the token length of an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592b9f6a",
   "metadata": {},
   "source": [
    "<div style=\"\">\n",
    "    <img src=\"assets/retrievers.png\" alt=\"Vector database Pipeline\" width=\"75%\" style=\"background-color: white; padding: 10px; border-radius: 5px;\">\n",
    "    <p>Source: <a href=\"https://www.clarifai.com/blog/what-is-rag-retrieval-augmented-generation\">https://www.clarifai.com/blog/what-is-rag-retrieval-augmented-generation</a></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903c1f9c",
   "metadata": {},
   "source": [
    "##### How Do Retrievers Work?\n",
    "\n",
    "Retrievers primarily work by:\n",
    "- **Chunking**: Breaking down large documents into smaller, manageable pieces (chunks).\n",
    "- **Embeddings**: Converting these chunks (and query) into numerical representations (vectors) using embedding models.\n",
    "- **Datastore**: Storing these embedded chunks in a specialised database (like a vector database) for fast searching.\n",
    "\n",
    "When a query comes in, its embedding is compared to the stored chunk embeddings to find the most similar (relevant) chunks. This search can be:\n",
    "- **Semantic**: Based on the meaning or context of the words.\n",
    "- **Syntactic**: Based on keyword matching or exact phrases.\n",
    "- **Hybrid**: Combining both semantic and syntactic approaches for comprehensive results.\n",
    "\n",
    "The retriever then calculates similarity scores between the query and the chunks. It retrieves the most relevant chunks by either:\n",
    "- Selecting the **top-k** (e.g., top 3, top 5) most similar chunks.\n",
    "- Applying a **threshold** to the **similarity score**, only retrieving chunks that exceed a certain relevance level.\n",
    "\n",
    "<!-- Add other databases, emebdding models, chunking -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6edf5",
   "metadata": {},
   "source": [
    "#### Creating database using ChromaDB & Nomic Emebeddings. (No chunking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85682ec",
   "metadata": {},
   "source": [
    "Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "120c6724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5cfc41",
   "metadata": {},
   "source": [
    "Creating Persistent ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc6e9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLLECTION_NAME = \"malta_news\"\n",
    "CHROMADB_PATH = \"data/chromadb\"\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path=CHROMADB_PATH)\n",
    "collection = chroma_client.get_or_create_collection(name=COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8187eb1e",
   "metadata": {},
   "source": [
    "Initialising Nomic embedding model (Text to numerical respresentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05108fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "MODEL_EMBEDDING = \"nomic-ai/nomic-embed-text-v1\"\n",
    "embedding_model = SentenceTransformer(MODEL_EMBEDDING, trust_remote_code=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60798567",
   "metadata": {},
   "source": [
    "Embedding the document texts for similarity matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8c28cf0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "557ba8c599f14a529844bc986a0e9546",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding the documents\n",
    "\n",
    "embeddings = embedding_model.encode(\n",
    "    sample_documents,\n",
    "    device=device,\n",
    "    # batch_size=EMBEDDING_BATCH_SIZE,\n",
    "    show_progress_bar=True,\n",
    "    normalize_embeddings=True,\n",
    "    # task_type='search_document', # Uncomment if your model requires a specific task type\n",
    ").tolist()\n",
    "\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da52986d",
   "metadata": {},
   "source": [
    "Adding documents into ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a068195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding to chroma collection\n",
    "# Each document contains: id, embedding, documents, and metadata\n",
    "\n",
    "num_docs = len(sample_documents)\n",
    "collection.add(\n",
    "    ids=[f\"doc_{i}\" for i in range(num_docs)],\n",
    "    embeddings=embeddings,\n",
    "    documents=sample_documents,\n",
    "    metadatas=[{\"source\": \"malta_news\", \"id\": f\"doc_{i}\"} for i in range(num_docs)],\n",
    ")\n",
    "# 'add' will not overwrite existing documents with the same IDs.\n",
    "# If you want to overwrite existing documents, use `upsert` instead of `add`.\n",
    "\n",
    "# Show the number of documents in the collection\n",
    "collection.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb0ed4c",
   "metadata": {},
   "source": [
    "Format output of chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b2c471a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_document_results(results):\n",
    "    formatted = []\n",
    "    docs = results['documents'][0]\n",
    "    metadatas = results['metadatas'][0]\n",
    "    scores = results.get('distances', [[None]*len(docs)])[0]\n",
    "    for idx, (doc, metadata, score) in enumerate(zip(docs, metadatas, scores)):\n",
    "        formatted.append(\n",
    "            f\"{idx}: {doc} (Source: ID: {metadata['id']}, Score: {score:.4f})\"\n",
    "        )\n",
    "    return \"\\n\".join(formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f361d46",
   "metadata": {},
   "source": [
    "Semantic search (Cosine Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "077131b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **Query**\n",
       "```\n",
       "News about Malta national football\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### **Results**\n",
       "```\n",
       "0: The Malta national football team is set to compete in the upcoming UEFA Euro 2024 qualifiers. (Source: ID: doc_2, Score: 0.5045)\n",
       "1: The Europa League first qualifying round is played this evening and Malta is being represented by Sirens FC. (Source: ID: doc_1, Score: 0.7072)\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Embedding the question and querying the collection\n",
    "question_embeddings = embedding_model.encode(\n",
    "    question,\n",
    "    device=device,\n",
    "    normalize_embeddings=True,\n",
    ").tolist()\n",
    "\n",
    "# Querying the collection\n",
    "document_results = collection.query(\n",
    "    query_embeddings=question_embeddings,\n",
    "    n_results=2,\n",
    "    # include=[\"documents\", \"metadatas\"]\n",
    ")\n",
    "\n",
    "display(Markdown(f\"### **Query**\\n```\\n{question}\\n```\"))\n",
    "display(Markdown(f\"### **Results**\\n```\\n{format_document_results(document_results)}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d41ff1",
   "metadata": {},
   "source": [
    "#### Combing Retrieval and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6034621a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### **System Prompt**\n",
       "```\n",
       "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### **User Question and Sources**\n",
       "```\n",
       "Question: News about Malta national football\n",
       "Contexts:\n",
       "The Malta national football team is set to compete in the upcoming UEFA Euro 2024 qualifiers.\n",
       "The Europa League first qualifying round is played this evening and Malta is being represented by Sirens FC.\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### **Response**\n",
       "```\n",
       "The Malta national football team is set to compete in the upcoming UEFA Euro 2024 qualifiers. Sirens FC is representing Malta in the Europa League first qualifying round.\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieval\n",
    "document_results = collection.query(\n",
    "    query_embeddings=question_embeddings,\n",
    "    n_results=2,\n",
    "    # include=[\"documents\", \"metadatas\"]\n",
    ")\n",
    "document_texts = document_results['documents'][0]\n",
    "documents_str = \"\\n\".join(document_texts)\n",
    "\n",
    "# Prompt engineering\n",
    "question_and_sources = f\"Question: {question}\\nContexts:\\n{documents_str}\"\n",
    "\n",
    "# LLM\n",
    "response = google_client.models.generate_content(\n",
    "    model=MODEL_CHAT,\n",
    "    contents=question_and_sources,\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt,\n",
    "        max_output_tokens=300,\n",
    "        temperature=0.3,\n",
    "        # safety_settings=[\n",
    "        #     types.SafetySetting(\n",
    "        #         category='HARM_CATEGORY_HATE_SPEECH',\n",
    "        #         threshold='BLOCK_ONLY_HIGH',\n",
    "        #     )\n",
    "        # ],\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Prints\n",
    "display(Markdown(f\"### **System Prompt**\\n```\\n{system_prompt}\\n```\"))\n",
    "display(Markdown(f\"### **User Question and Sources**\\n```\\n{question_and_sources}\\n```\"))\n",
    "display(Markdown(f\"### **Response**\\n```\\n{response.text}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0141a02",
   "metadata": {},
   "source": [
    "---\n",
    "### Can we streamline the entire pipeline?\n",
    "\n",
    "Streamlining the RAG chatbot pipeline is crucial for improving performance and scalability, ensuring chatbots can efficiently provide accurate, real-time information. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83487d06",
   "metadata": {},
   "source": [
    "## Chatbot #3\n",
    "### *Streamlining with LangChain and LangGraph*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d67fe83",
   "metadata": {},
   "source": [
    "**LangChain** is a modular framework for building complex AI workflows, while **LangGraph** extends LangChain by providing a graph-based, stateful approach to orchestrating workflows, particularly for agentic AI patterns involving cyclical workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b99dfea",
   "metadata": {},
   "source": [
    "Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9772c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langgraph.prebuilt import ToolNode, create_react_agent\n",
    "from langgraph.checkpoint.memory import MemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dcea12",
   "metadata": {},
   "source": [
    "Creating langgraph pipeline.\n",
    "\n",
    "Note that Chromadb still requires pre-processing of raw document texts and embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9027f04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "llm = init_chat_model(\n",
    "    MODEL_CHAT,\n",
    "    model_provider=\"google_genai\",\n",
    "    temperature=0.7,\n",
    ")\n",
    "\n",
    "# -- Retrieval tool --\n",
    "\n",
    "# Embedding model with langchain\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=MODEL_EMBEDDING,\n",
    "    model_kwargs={\"device\": device, \"trust_remote_code\": True},\n",
    ")\n",
    "\n",
    "# Chroma database with langchain\n",
    "vector_store = Chroma(\n",
    "    persist_directory=CHROMADB_PATH,\n",
    "    embedding_function=embedding_model,\n",
    "    collection_name=COLLECTION_NAME,\n",
    ")\n",
    "\n",
    "# Setting up function tool for retrieval\n",
    "def retrieve_tool(query: str):\n",
    "    \"\"\"Search a high-quality knowledge base for facts relevant to the user's query.\"\"\"\n",
    "\n",
    "    # Search documents using chromadb vector store\n",
    "    vector_store_result = vector_store.similarity_search_with_score(\n",
    "        query,\n",
    "        k=2,  # Number of documents to retrieve\n",
    "    )\n",
    "    # Format the results\n",
    "    retrieved_docs_with_scores = [(document, float(score)) for (document, score) in vector_store_result]\n",
    "\n",
    "    # Get string for prompt engineering\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc, score in retrieved_docs_with_scores\n",
    "    )\n",
    "\n",
    "    return serialized, retrieved_docs_with_scores\n",
    "\n",
    "# Creating tool with retrieve function. Note that other tools can be added to the ToolNode.\n",
    "tools = ToolNode([tool(response_format=\"content_and_artifact\")(retrieve_tool)])\n",
    "\n",
    "# Memory for chat history and conversational context\n",
    "memory = MemorySaver()\n",
    "\n",
    "agent = create_react_agent(llm, tools, checkpointer=memory, prompt=system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99d277c",
   "metadata": {},
   "source": [
    "Showing Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e23f6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXdcFNf+v89sb7QtdBAsiIiKATUSY8OYYETF3m4sv1y9liQkGu81ucbc5KvGG3M1otFg9EaJigXEHkUTQUEiqKAUQUFQelu2953fH+uLcHGp7uycZc/zyh+7O7Nz3hsez3zmzMwZDMdxgECQDYXsAAgEQCIiYAGJiIACJCICCpCICChAIiKggEZ2AOjQqg0NlVqlzKCU6Q16XKe1geEtJptCY2AcBxrHgeLmyyY7Tk/A0DiiCaVc//iuvDRP0VSjcXZlcByoHAeaI5+m09jA/x86iyKu0SplehoDKy9U9g3m9R3K7TeUR3auboBEBDiOZ5xvrClTiXxYfYO53gM4ZCd6JbRqY2me/HmRqvKJKjxKEPCaA9mJuoS9i1j4h/R6Ql14lOC1iS5kZ7EwMrEu43yjUqaf/Bd3riPsNZhdi5iWVE+lgzeiRGQHIZCmWk3y3qpJC918A6Hu6e1XxN9P1fHdGMPGOpMdxBqc3V/5+hSBmy+L7CDtYqcino+r8hnICRlnFxaaOLuvMnCE48AwSEtGexxHzDjf4NmPbVcWAgCmr/K695u4oUpDdhDz2J2Ij+/LAAChEb3t0KQrLNjgm5ZUjxth3AfanYipifXDJ9ijhSb6DuHdOttAdgoz2JeI92+IA8Mc2Twq2UFII2Sc8+P7coVUT3aQttiXiGX5itFRfLJTkMzYmcKc1GayU7TFjkQsK1DQ6BQq1Y5+sll8A7l56RKyU7TFjv4qTx8q/IdwrdzoP/7xj7Nnz/bgi2+99VZlZSUBiQCDRRF5MyufqIjYeI+xIxGb6rT9rC5iQUFBD75VXV0tFosJiPOCgOG8iidK4rbfA+xFRK3a2FCpYfOIOuWanp6+cuXKMWPGzJgxY/PmzQ0NDQCAsLCwqqqqr7/+evz48QAAuVy+f//+JUuWmFbbuXOnWq02fT0iIuL48eN//etfw8LCUlNTo6KiAADTp09ft24dEWm5TvT6CsgGFHH7oKlWE7+ljKCNFxYWhoaGHjhwoLq6Oj09ff78+WvWrMFxXK1Wh4aGJicnm1Y7cODAqFGjUlJSsrKyfvvtt8jIyO+//9606O23354zZ863336bmZmp0+lu3rwZGhpaUVFBUODaclXCd88I2njPgP2iDEuhkOi5TkT92JycHBaLtXz5cgqF4u7uHhQU9OTJk5dXW7x4cUREhL+/v+ltbm5uRkbGhx9+CADAMMzJyWn9+vUEJWwD14mmkMA1gmMvIhqNgMEmqg4JCQlRq9UxMTGjRo0aO3asj49PWFjYy6vR6fTbt29v3ry5uLhYr9cDAPj8P8eSgoKCCIr3MhQaxmDBVZXBlYY4uI5USb2OoI0HBgbu3r1bJBLFxsZGR0evXr06Nzf35dViY2Pj4uKio6OTk5Ozs7OXLVvWeimDwSAo3ssomvVUGma15rqCvYjIcaQpiTydEB4evmnTpvPnz3/55ZcSiSQmJsbU57WA43hiYuK8efOio6Pd3d0BADKZjLg8HaOQ6mG7VNZeRGRzqUIvpl5nJGLjd+/ezcjIAACIRKKpU6euW7dOJpNVV1e3Xken06lUKldXV9NbrVablpZGRJiuoFEaXX2YZLVuFnsREQDA5lFLHyqI2HJubu6GDRuSkpLEYnFeXl5CQoJIJPLw8GAyma6urpmZmdnZ2RQKxc/P79y5cxUVFc3NzV999VVISIhUKlUozETy8/MDAKSkpOTl5RERuPiezK0PXBfJ2pGI/sHcp3mEiLh48eLo6OgdO3a89dZbK1as4HK5cXFxNBoNALB8+fKsrKx169apVKqtW7eyWKzZs2fPmDFj5MiRa9euZbFYkyZNqqqqarNBb2/vqKio/fv3x8bGEhG4rEDpP9jaY/sdY0dXaGs1xosHq6NXe5EdhGSeFSlLH8rHz3YlO8j/YEc9IoNJcfVm3vuNwFNnNkHGuYbBo53ITtEWuA6diCZ8qmDv+pL27hw1Go0TJ040u0ir1dLpdAwzM+TRt2/fQ4cOWTrpC3JycmJiYrobKSAgIC4uzuy3iu/JXNwYIi+4jlTsa9dsIjet2WjEh48372J7QyoajYbJNP/HwzCMxyNwToUeRKJQKFyu+RLw4sGqN6NFjny6RTNaALsTEQBw6VD1wDAH25qRwyLA/MPtqEZsYcpyj9sXGuueq8kOYlVSE+sFHgw4LbTTHvHFeY7vK15/V2DrM910kdTEeldf5qARjmQHaRd77BFNhd3sGJ+sq+L8TOgumrcsOI6f3VfpyKfBbKH99ogt3L7Y8DRfGT5V4BcE1wCvRchOacrPlE6Y6+o7EPaO395FBAA0VmkyLjQy2RSvAWz/wVyOg80PadVXaMoLFXevi4e+6Twqkk+hwHWhjVmQiC+oLFEVZcme5itc3Oh8NwbXicZ1pHGdqAYD2cm6AIbhsia9QmrAjXjxPTmLS+k/jDf0TWfYLjrsACRiW2rKVPWVWoVEr5DqKRRMKbOkiSqVqrS0dPDgwRbcJgCA50IDOOA6Uh1caJ792A4u0A0TdgoS0aqUlJRs3Ljx5MmTZAeBDpvpuhG9GyQiAgqQiAgoQCIioACJiIACJCICCpCICChAIiKgAImIgAIkIgIKkIgIKEAiIqAAiYiAAiQiAgqQiAgoQCIioACJiIACJCICCpCICChAIiKgAImIgAIkIgIKkIgIKEAiWhUMw1qecIFoDRLRquA4XldXR3YKGEEiIqAAiYiAAiQiAgqQiAgoQCIioACJiIACJCICCpCICChAIiKgAImIgAIkIgIKkIgIKEAiIqAAiYiAAiQiAgrQA3+swfz585VKJQBAq9U2NjZ6eHiYHkF/5coVsqPBAuoRrcH06dNramqqqqoaGhpwHK+qqqqqqnJwcCA7F0QgEa3B/PnzfX19W3+CYdiYMWPISwQdSERrgGHYzJkzqVRqyyd9+vSZN28eqaHgAoloJebOnevj42N6jWHYuHHjTJUiwgQS0UrQaLT58+czmUwAgLe39+zZs8lOBBdIROsxc+ZMb29vAEB4eDjqDttAIzsAdBiNeHO9TtqgMxIwrhUV8X6KMWX8yHmleQqLb5xOx/geDK6jTf5N0Tji/1B0V5aXLlHKDZ7+HIVUT3ac7sF2oD4rVLj1YY2fLeI525iOSMQ/eZQtLbqrGD/XnULByM7Sc8R1mrRTNdFrvLhOtuQiqhFfUPJAXnhHPnG+h01bCABwcWVOXel7+OsysoN0DyTiCx7cbH5jei+ZlYZKw0ZGiu5caSQ7SDdAIgIAgFppqK/Qsnm2tC/rGJ4zrfqphuwU3QCJCAAA0kadex822SksiYOAYTTYUvWPRDSBKWQ2dozcMbgBKCS29IuQiAgoQCIioACJiIACJCICCpCICChAIiKgAImIgAIkIgIKkIgIKEAiIqAAiYiAAiQiAgqQiDbAmeST27ZvJjsFsSARbYCiogKyIxBO77kU1MrI5fJTp3+5k3W7rKxEwBeGh49bvmwVi8UCABiNxu93b7+VfoNBZ0REvBM8eNjGz2MST13h8wV6vf7goR8y/7hVV1cTHBwSPX3u66+/mHhkxsxJy5b+TSJpPnwkjs1mjwgbvXbNeoFAGPPJitzcewCAq1cvnj97g8fjkf3TCQH1iD0k6UzCseM/z5v7l61bdq1c+dGN1JTDR+JMi06dPnr+QtIHaz/dv/8XNptz8NAPAAAKhQIA2B3779OJx6JnzDt29Py4sRGb/7UhNe266Vt0Ov3EiSMUCiX5zPXD/018mJfz8+EfAQC7/hM3aFDw5Mnv/n49u7daiHrEnjN3zuJxYyP69PE3vc3Ly72TlbFyxYcAgCtXL4x9c+L4cZMAAIsWLruTlWFaR6PRXLl6YeGCpdOiZgEApkROz8vLPRJ/YNzYCNMKXl4+ixctBwAAnsOIsNHFxYWk/Tyrg0TsIXQ6PSv79jfbNz8pKdbr9QAAFxc+AMBgMJSVlUa+M61lzbFvRjx4cB8AUFxcqNVqR4SNblkUMiz08q/nJFKJk6MTACAgYFDLIgcHR4VCbvWfRRpIxB4SdyD20qXklSs/GhE22s3N/aeDey9dPgsAkCvkOI5zONyWNZ2cnE0v5HIZAOCDj/5fm02JmxpNImKYbd/J+iogEXsCjuPnLyTOnrVw6rvRpk9MkgEAOGwOAECn07WsLBa/uK1TIBQBANZ98rmXl0/rrbm6ulsxO6QgEXuCwWBQqVRC4Yv7oLVabcbtNNNrOp3u6upWVlbSsnJ6RqrphbeXr2k2sOEhYaZPxOImHMc5HI7VfwF0oKPmnkCj0Xx9/S7/eq6yqkIiaf73jq+GBIfIZFKFQgEACB899mrKxazsTBzHT50+KpNJTd/icDhLl6w8En/g4cMcrVabmnZ9/YbVu77/ptPmvLx8Cgvz7t3P0mq1xP84ckAi9pBNn29lMVlLl81e/N6M0NdGvv/+WhaTFT1rUnVN1ZL3VgwZMnzD39f+5b3o8vKns2ctBADQaHQAwPx57326/otjCT9HTR///e7tnh7e69b9s9O2ot6diWHYpxvWKJWWn0MMEtAkTAAAUPdccz2hbuoKny6s2zlqtbqursbX18/0NuHEkaNHD50/d8MiG+8ikgbdjRNViz/rY81GXwXUI1qehBNHVvxtUWJSgkTS/NvvV0+e+mXaNDQ/bCeggxXLs3TJColEfPXqhQM/xYpEbtEz5i1auIzsULCDRCSEjz78O9kRbAy0a0ZAARIRAQVIRAQUIBERUIBEREABEhEBBUhEBBQgERFQgEREQAESEQEFSEQAAKBQMUd+rzrbiRtxvjuT7BTdAIkIAABCT0ZZgcJIxPNISaKxWk1j2NIdMEjEFwSOcKx+qiQ7hcVoqtH4B9vSHQhIxBdMnCe6lVSrktvSQ3La4/7vjbgBHxDiQHaQboCu0AYAgKKiIqlUOmxIaPyW8mHj+TxnurMrAzeSHaubGI14Q6W6sUoNjPjE+Tb2gEskInjy5MkXX3xx6NAh08w12deaKh6rAI5J6i1/p5IRx3U6HZPBsPiWAQB8T+ajorwGVb7PIJqfn5+fn19gYCCNZhsHYXYtYkVFhbe3d0lJSb9+/azTYklJycaNG0+ePEnQ9jdu3HjlyhUMw1xcXHg8HpPJ9PT0DAgIWLVqFUEtWgr7FfHWrVvffvvt2bNnrdmoTCa7e/fu+PHjCdr+o0ePYmJiGhoaWn9oNBo9PDwuXrxIUKMWwR4PVuRyuckJK1sIAHBwcCDOQgBAYGDgoEGD2nzI5XIht9AeRTx37ty2bdsAAJGRkdZvvb6+/ocffiC0iYULF7q4uLS8pVAoN2/eJLRFi2BHIpqKkKKioi1btpCVQSqV3rhB7A3OI0aM6Nevn+nHGo3Gvn37Wr/j7wH2ImJKSkpycjIA4NNPPyUxhqur6+rVq4luZe7cuU5OTgAAHx+fhISE3NzcrVu3Et3oK2IXByulpaVxcXHffNP5LDO9hkWLFtXW1l67ds30NjEx8cyZM7/88gvZudoH79XcunWroaGhqamJ7CAvqKur27t3LylNFxQUhIaG5uXlkdJ6p/TmXfP169dPnDghEAhaF+/kYoUasT0GDRqUnZ29ffv206dPkxKgY3rnrrm4uDggIODhw4dDhgwhO8v/QPQ4YlfYtm2bVqvdvBmuB7f0QhEPHz5cXl7+xRdfkB0EXs6dO3f06NH4+HgGMScbewLZtYElMdWCZ8+eJTtIu5BYI7bh8ePHr7/++v3798kO8oLeUyMeOHDAdJA4bdq0LqxODiTWiG3o37//7du3Y2Njjx07RnYW0EvGEXU6XVVVlcFgmDNnDtlZOsE644hd5+DBg9XV1f/8Z+ez1hKNzdeIx44dGzlypK+vL0Tljq1x+fLlAwcOxMfHc7ncLqxOCLbdI6akpFRXV/fv399WLLTCueYeEBkZuXPnzsjIyKysLLIy2KqIV69eBQAMGTJk3bp1ZGfpBvDUiG3o06dPWlrawYMHDx8+TEoAmxRxz549Dx8+BAC4u9vYo3JgqxHbsH//folEsmHDBhLaJvuwvXsUFhbiOJ6bm0t2kN7MtWvXpk6dKhaLrdmoLfWImzZtKigoAAAMHTqU7Cw9BM4asQ0RERE//vjjrFmz0tPTrdaobYgoFotVKtXo0aNnzpxJdpZXAtoasQ2enp6mM/U//fSTdVq0ARG3bdtWWVnJZrOnTJlCdpZXBfIasQ27d+/W6XQff/yxFdqCfRwxNTW1vr5+9mz0wBzSSEtL27JlS3x8vKsrkfdKW7Mg7RaxsbE4jqtUKrKDWBJ4zjV3i/r6+nfeeScnJ4e4JiDdNSclJTU1NQEATDe99xpYLNb9+/fJTtFthELh5cuX9+7dW1lZSVATkO6a1Wo1jUazlVkKuoVOp9Pr9RiG2dy/sbCwsKysLAwjZJIxSHtEFovVKy00PVmczWafOHGiurqa7Czd4NGjRwMHDiTIQnhF3LVrV1JSEtkpCGTJkiUxMTFkp+gGhYWFL9+6b0EgFVGr1ep0OrJTEMuJEycAAM+fPyc7SJcoKCgICgoibvuQivjxxx/PmjWL7BTWIDU19e7du2Sn6Bw77RHpdHpvrRHbsHjx4suXL5OdonMePXpkjyL2+hqxNaYLpDMzM8kO0i4FBQWEWgiviPZQI7ahoqLiypUrZKcwD9H7ZXifYP/xxx8TN1IAJ7Nnzz516hTZKcxTUFBA9B3ikPaI9lMjtsZ089fx48fJDtIWK/SIkIpoVzViGwQCAVSzghiNxsePHw8cOJDQViAV0Q5rxBYmT57s5+dHdoo/IXoE0QSkItrPOKJZwsLCAACQzJpihf0yvCLaZ43Yhujo6KNHj5Kdwr5FtOcasYXhw4dPmDCB7BT2vWu25xqxNZ6enqaukawAer3+6dOnAwYMILohSEW08xqxDfv374+Pj2/9yeTJk63TtHW6Q3hFRDVia9zc3ObNmyeXy1UqFQBgypQpjY2Nn332mRWatk6BCO+ZlV27dvn6+tr6zaMWhMFgMBiMMWPGODs719XVYRiWn5/f1NTE5/MJbbegoGDEiBGENmEC0h4R1YhmEQgENTU1ptdNTU1WeJKP1XpESO9Z0el0GIahvXNrZs2aVV5e3vLWaDSGh4fv2bOHuBa1Wu24ceNu375NXBMtQNojohqxDdHR0U+fPjUa/3yGNIVCKS8vLy0tJa5Rqx2pwCsiGkdsw5kzZ6Kjo/38/JydnU3dIQCgtraW0L2z1fbL8B6soBrxZTZt2gQAePDgwc2bN2/evNnY2CgRK1Ov35k5bRFBLRblPxs+fLhMrO/xFnAcOPK75BhcNeLEiRMlEklLJAzDcBx3d3e/dOkS2dHgIjul6cEtsRHT6zU4m7D7o/V6PZVGe5XLQl08mJWPlf2HcUdNETjy6R2sCVePGB4efunSJQrlz4KBQqFERUWRGgo6fj1cw+PTI5f78pw7+tNCgl5nbK7Tnvq+YuYaLxfXdmeYhqtGXLBggemkVgve3t4LFiwgLxF0XP65xsWdOWyswCYsBADQ6BShF2vuJ/5n9lZKm9ott+AScfDgwcHBwS1vMQx75513TOU5AgBQVqBgsKlBr8PyaMFuMWGeR+alpvaWwiUiAOC9994TCoWm197e3nPnziU7EUTUPdfQmdD9ybqIixvzSY6svaXQ/aqgoKCWmYkjIyPhebAoDGiUBqEHk+wUPYRKw3wHcpvrtWaXQiciAGDp0qUCgcDd3R11h21QSA16Wx7UaqrVtndz5qseNVeVKCUNeoVMr5QajAag1xu78KVOEYwZuIrL5WZf1gBQ++qbY7IpGMA4jlSOI1XgyRR52mqn0ovpoYjlhYrie/LSPIWLOxvHMSqdSqFTKVSqpUYlg4eOBwDIFBbZGJArMaPBYKjUG7RqnVqiUxv6DeUGhjm49bGxGQp7Md0WsfqpKu1MI53DwGjMfqNdaHQqMcEIRKvSNzYoUpPFbA54c4bAWWQbj0/r3XRPxGvH66tK1QJ/PtfFhvsSBpvG93ECAEjrFImxVYNGOoRPFZAdyt7p6sGKXmf8+atytYHp+5qnTVvYGkdXbr/RPnU1lDN7iZoaGtFFuiSiQY/HbSz1CHLjCUh7jCpxOHs50p0cE3bYxoSZvZXORTQa8X0bSoIi/Jlc2zin1AN4Ao6jF//w/5V3YV0EIXQu4tFtzwaEe1klDJlwnFl8H+eLB21pgvXeRCci3khscPZxZnLt4rjSwZWnA8yc1Gayg9gjHYnYWKV5mqdwEPGsmIdknD2dbiU3QHWNpp3QkYhpyY1Cf2LvVoQQ9wCXm8mNZKewO9oVsaZMpTdQHEQc6+bpKjkPr63fNEquEFt8y0I/58pSjUZlsPiWbZQZMycdiSf8YbntivgkV4FRe+1hcidglLJ8JdkhLMO/vvrHpctnyU7ROe2KWPJA4eAKaXdINBw+93GOnOwUlqGoqIDsCF3C/Ck+cZ2W7UAn7mC57NmDq7//9LyigMd1GTRwzOQJ77NYXABAeuaplNRDq5bvO5Kwsbau1MOt/9jwBSNem2r61oVfY7NzLzEZnOFD33YV+hKUDQDg6MqpzpcSt32rMSEiDADw7Y6v9+3fef7sDQBAenrq4SNx5c+eOjk59+8/8KMP/u7m5m5auYNFLWT+kX7ixJFHRfl8vjA4eNiK9z8QCIQWiWq+R5Q369Uqi1zQZYaGxuc//vyBTqdZu+KnJQu3V9c+3ndolcGgBwBQaXSVSpZ8ccfcGZ99+1Xm0OCJJ5P/T9xcAwDIuJOYcef0zHc//WjlfwUunim/HyQonukWBblYp5D2/DZKSPj1UjoA4NP1m0wWZt/944svP508+d2TCZc2b/qmtrZ61+5vTGt2sKiF4sePNn720fDhI34+dPrDDzaUlBRv//eXlopqXkSl1EAl7LKae7m/0qj0pQu2u4n83F37zpn+eWV1UV5hqmmpwaB7a8L7fXyGYBgWFvIujuOV1cUAgFu3Tw4dHDE0eCKH4zjitan9+4YRFM8Eg0VVSGxexDYc+u++sW9OnD1roZOT8+DBQ1ev+iQz89ajooKOF7WQ9zCHxWItXrTczc191Mjw777dt2DBUktla0dEmZ7KIOpO07JnD3y8g7jcF7dE8V08BHzvp+U5LSv4eg02veCwHQEAKrUMx/GGpudurv4t63h7BhIUzwSdTVXafo/YhtLSx4GBg1veDgwIAgA8epTf8aIWgoeEqNXqjZ/HnDp9tKLyuZOT8/AQi3UH7dqGAaIGdVVq+fPKgvWbRrX+UCr7c+ju5avJ1RqF0WhgMv88eGIw2ATFM2E0ANC7njgkl8s1Gg2T+eeVUxwOBwCgVCo6WNR6CwEDAr/Ztjst7Xrcgdgf9u0MfW3k0iUrg4OHWSSeeRE5jjSDTm2RBl7GwUHg3yfk7YkrWn/I5Tp18BUWk0uhUHWtImm0xA6vGLQGriNcsw+8IiwWCwCgVqtaPlEoFQAAAV/YwaI2Gxk1MnzUyPBlS/929+4fiUnHP/s85kzSNSrVAlWc+V0zx4Fq0BE1ouvpNqBZUtPXb3j/vqGm/3g8F1dhR08WwTDMxdmj7NnDlk8Ki9IJimdCqzZwHG3v4vMOoNFoAwMG5ec/aPnE9LpvvwEdLGq9hZycu3/cyQAACIWit9+eumb1Oplc1tBQb5F45kV05NPoDKJ2TGPDFxiNxnOXd2q16rr68gtX9ny3Z2F17ZOOvzUseNLDgt9zHl4DAPx280h5RR5B8UxXvvGcab2gR2QymSKRa3Z25v2cbL1eHz1j3q30G4mJx6Uy6f2c7B/2/ee14SMG9B8IAOhgUQt5+blf/mvD+QtJzc3igsK8pDMJQqFIKBRZJKr5/9dOQoZebVDLtCwHyw8lcjiO69ce+/1m/K79S+rqy3y9B8+Z8XmnBx+Txi1TKMTJl7775eTn/n1CpkXGHDv1BUFXJ0hrFS6uveSs0qKFy//78/47WRnHj12YPPnd+oa6E6fi9/zwnZube1jo6399f61ptQ4WtTB3zuLmZvGevTv+s3Mrg8GYOOHtnf+Js8h+uaPZwG5fbKwow0V97fH+9qr8uhERvAHDHcgO0pZfD9d49uP5D7HV66HOxJZP/5unk9DMP/J2T/H1H8bF9b1t/KKLYJjBf3AvvCkCZtotg0TeLDYHl9QqnNzM/0maJXU79pifp4vN5Kk05s/Vuov6rl1xoKdpzfDPLRHtLTIY9FSqmR/o6z14xZLd7X2rvlTsH8SmMWCcA6MX01E9Pnam8PSuyvZEdODxP1kdb3aRVqtmMMzf6UehWPgIoL0MAACtTsOgm5nUgUZrt/A1Goz1TyVz1vSzXEBEl+hICycBfdAoXmO9zEFkplqiUml8F09z37Mqls0grZaMn2OZs/iIbtHJDih8qlDZIFc2EzW4DRWSaimPawwa1dHQOoIgOq+E5n3i/ex+jU7dyw9cmmvkqib5pIWuZAexU7pUkq/c3vdx+vNe3C9KauRArZi/3ofsIPZLl0TEMGz1jv7SyiZpbbszftou4udiBqaasYr8etee6cYgxfz1PgKBoTSzQlpnoeniyEZcKX10o9x/IC1yadtLkRFWpnuDKW9ECYJGOaSdaWwoUeJUuqOIa4vzkKikGlm90qjRCD3pU77sw2T3qosbbJRuj+q5uDKmr/SoKVM/zpGXPKhlcmhGI0ZlUKl0KoVGBYRdxfgqYBim1xmMWr1ea9CqdEw2ZUAIL+A1EZoZER56OLzs7sdy92O9OUPYVKOVNOgUUr1CojfojQY9jCIyWBiFSuE6cjiOVKEXg+dke714r+dVz3Pw3Rl8d9SvIF4VdEbVluA60Wx60gO+O7O94g2JaEuwuZSGSg3ZKXqITmusKFY4Cc3vP5GItoRbH5ZOY6uT8jTVaDq4xBOJaEv4BHAwDNz/zSYnK/vtWNUb09qdNB+u5zUjukJaUr1Oh/cb6ijwtIFZ9RW6zPHgAAAAZ0lEQVRSvaRe83tCzV8+9+W2P16BRLRJ8m5L8jOkaqVBQ9jMMBZB5MVsrtP6D+G+ESXs+HGWSEQbBseBVg21iLgRZ3G7dOIKiYiAAnSwgoACJCICCpCICChAIiKgAImIgAIkIgIK/j88u/2J087bqAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "image_data = agent.get_graph().draw_mermaid_png()\n",
    "with open(\"assets/graph.png\", \"wb\") as f:\n",
    "    f.write(image_data)\n",
    "display(Image(\"assets/graph.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "650d50aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "News about Malta national football\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_tool (a821044a-40d5-4ef4-adc6-12042c1336fd)\n",
      " Call ID: a821044a-40d5-4ef4-adc6-12042c1336fd\n",
      "  Args:\n",
      "    query: News about Malta national football team\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_tool\n",
      "\n",
      "Source: {'id': 'doc_2', 'source': 'malta_news'}\n",
      "Content: The Malta national football team is set to compete in the upcoming UEFA Euro 2024 qualifiers.\n",
      "\n",
      "Source: {'id': 'doc_1', 'source': 'malta_news'}\n",
      "Content: The Europa League first qualifying round is played this evening and Malta is being represented by Sirens FC.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The Malta national football team is set to compete in the upcoming UEFA Euro 2024 qualifiers. Additionally, Sirens FC will represent Malta in the Europa League first qualifying round this evening.\n"
     ]
    }
   ],
   "source": [
    "input_message = question\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config={\"configurable\": {\"thread_id\": \"test\"}},\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555556d7",
   "metadata": {},
   "source": [
    "### Benefits of LangChain & LangGraph\n",
    "- Formatted and algined input/output\n",
    "- Automatic pipelining management\n",
    "- Advanced tool calling:\n",
    "    - Multiple retrieval calls.\n",
    "    - Fine-tuning of retrieval queries.\n",
    "    - Intelligent recognition of unnecessary retrieval calls, leading to cost and time savings.\n",
    "- Observability and Debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d6d816",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Is logging an option, and can we track model costs?\n",
    "\n",
    "Logging helps a lot for identifying user questions, retrieved documents, LLM responses, tool calls, latency, and errors. This data is vital for debugging, performance monitoring, and improving the chatbot's accuracy and relevance.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219d71bb",
   "metadata": {},
   "source": [
    "## Chatbot #4\n",
    "\n",
    "### *Adding Tracing (Langfuse)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1298194c",
   "metadata": {},
   "source": [
    "#### What is Langfuse?\n",
    "\n",
    "Langfuse is an open-source platform designed to observe and evaluate large language model (LLM) applications. This is used to trace the flow of information from the user query through retrieval, generation, and ultimately to the chatbot's response. It is beneficial because it provides visibility into the \"black box\" of LLM interactions, helping identify bottlenecks or errors in the RAG pipeline, such as poor retrieval results or hallucination.\n",
    "\n",
    "Langfuse also allows local deployment rather than using cloud services due to costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bc581d",
   "metadata": {},
   "source": [
    "#### How to deploy langfuse locally?\n",
    "\n",
    "1. Download and install docker [Docker](https://www.docker.com/).\n",
    "2. Ensure git is installed (or download the repository directly).\n",
    "3. Run the below commands:\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/langfuse/langfuse.git\n",
    "cd langfuse\n",
    "docker compose up\n",
    "```\n",
    "\n",
    "4. View the website at ```http://localhost:3000```\n",
    "5. Navigate to Settings/API Keys, 'Create new API keys'\n",
    "\n",
    "![Langfuse API Keys](assets/langfuse.png)\n",
    "\n",
    "Please note that langfuse is currently being updated and different code may be need to integrate the system depending on the versions.\n",
    "- Pip langfuse verion: 2.60.4\n",
    "- Docker langfuse version: 3.54.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb964d",
   "metadata": {},
   "source": [
    "Adding tracing to the chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d2c874",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "langfuse_handler  = CallbackHandler(\n",
    "  secret_key=\"sk-lf-46ff8cdc-ccd8-4b74-8c4c-94c83ab58a29\",\n",
    "  public_key=\"pk-lf-3a4eaa29-9ec1-4f47-b517-4f58be7bc0d2\",\n",
    "  host=\"http://localhost:3000\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecd87e8",
   "metadata": {},
   "source": [
    "Chatbot remains the same, just 1 line change for config to include the langfuse callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1832f937",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_message = question\n",
    "\n",
    "for event in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
    "    stream_mode=\"values\",\n",
    "    config={\n",
    "        \"configurable\": {\"thread_id\": \"test\"}, \n",
    "        \"callbacks\": [langfuse_handler]  # Added langfuse handler to the stream\n",
    "    },\n",
    "):\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
